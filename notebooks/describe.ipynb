{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import difflib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/df.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "total_token_count = df['token_count'].sum()\n",
    "print(total_token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['decade'].value_counts()\n",
    "\n",
    "most_frequent_class = class_counts.max()\n",
    "least_frequent_class = class_counts.min()\n",
    "imbalance_ratio = most_frequent_class / least_frequent_class\n",
    "\n",
    "total_samples = class_counts.sum()\n",
    "num_classes = class_counts.count()\n",
    "\n",
    "print(f\"Class counts:\\n{class_counts}\\n\")\n",
    "print(f\"Most frequent class count: {most_frequent_class}\")\n",
    "print(f\"Least frequent class count: {least_frequent_class}\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "print(f\"Total number of samples: {total_samples}\")\n",
    "print(f\"Total number of classes: {num_classes}\")\n",
    "\n",
    "gini_coefficient = 1 - sum((class_counts / total_samples) ** 2)\n",
    "print(f\"Gini coefficient: {gini_coefficient:.2f}\")\n",
    "\n",
    "class_probabilities = class_counts / total_samples\n",
    "entropy = -sum(class_probabilities * np.log2(class_probabilities))\n",
    "print(f\"Entropy: {entropy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_count = class_counts.median()\n",
    "q75 = class_counts.quantile(0.75)\n",
    "q25 = class_counts.quantile(0.25)\n",
    "iqr = q75 - q25\n",
    "\n",
    "print(f\"Median class count: {median_count}\")\n",
    "print(f\"IQR: {iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('decade').filter(lambda x: len(x) >= 10).decade.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['supercuration_name'].value_counts()\n",
    "\n",
    "most_frequent_class = class_counts.max()\n",
    "least_frequent_class = class_counts.min()\n",
    "imbalance_ratio = most_frequent_class / least_frequent_class\n",
    "\n",
    "total_samples = class_counts.sum()\n",
    "num_classes = class_counts.count()\n",
    "\n",
    "print(f\"Class counts:\\n{class_counts}\\n\")\n",
    "print(f\"Most frequent class count: {most_frequent_class}\")\n",
    "print(f\"Least frequent class count: {least_frequent_class}\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "print(f\"Total number of samples: {total_samples}\")\n",
    "print(f\"Total number of classes: {num_classes}\")\n",
    "\n",
    "gini_coefficient = 1 - sum((class_counts / total_samples) ** 2)\n",
    "print(f\"Gini coefficient: {gini_coefficient:.2f}\")\n",
    "\n",
    "class_probabilities = class_counts / total_samples\n",
    "entropy = -sum(class_probabilities * np.log2(class_probabilities))\n",
    "print(f\"Entropy: {entropy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_count = class_counts.median()\n",
    "q75 = class_counts.quantile(0.75)\n",
    "q25 = class_counts.quantile(0.25)\n",
    "iqr = q75 - q25\n",
    "\n",
    "print(f\"Median class count: {median_count}\")\n",
    "print(f\"IQR: {iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('supercuration_name').filter(lambda x: len(x) >= 10).supercuration_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"same_text\"] = df[\"text\"] == df[\"text_normalized\"]\n",
    "print(len(df))\n",
    "print(len(df[df[\"same_text\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas(original, normalized):\n",
    "    s = difflib.SequenceMatcher(None, original, normalized)\n",
    "    differences = []\n",
    "    for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "        differences.append((tag, original[i1:i2], normalized[j1:j2]))\n",
    "    return differences\n",
    "\n",
    "df[\"deltas\"] = df.apply(lambda row: get_deltas(row[\"text\"], row[\"text_normalized\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_dict = {\"replace\": 0, \"delete\": 0, \"insert\": 0, \"equal\": 0}\n",
    "\n",
    "for differences in df[\"deltas\"]:\n",
    "    for diff in differences:\n",
    "        tag = diff[0]\n",
    "        \n",
    "        differences_dict[tag] += 1\n",
    "\n",
    "differences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "for difference_type in differences_dict.keys():\n",
    "    all_replacements = []\n",
    "    for deltas in df[\"deltas\"]:\n",
    "        replacements = [diff for diff in deltas if diff[0] == difference_type]\n",
    "        all_replacements.extend(replacements)\n",
    "\n",
    "    if len(all_replacements) >= n:\n",
    "        random_replacements = random.sample(all_replacements, 10)\n",
    "    else:\n",
    "        random_replacements = all_replacements\n",
    "\n",
    "    print(f\"Random diffs for type '{difference_type}':\")\n",
    "    for replacement in random_replacements:\n",
    "        print(replacement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
